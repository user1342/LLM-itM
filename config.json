{
  "use_request_logging": true,
  "use_response_filtering": true,
  "use_content_moderation": false,
  "max_tokens_limit": "2048",
  "response_format": "json",
  "temperature_override": "",
  "system_prompt_prefix": "",
  "enable_caching": false,
  "log_level": "INFO",
  "llm_provider": "ollama",
  "default_model": "llama3.1",
  "use_translate_response":true
}
